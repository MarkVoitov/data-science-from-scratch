{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta = [alpha, beta_1, ..., beta_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_i = [1, x_i1, ..., x_ik]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_i, beta):\n",
    "    return dot(x_i, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x_i, y_i, beta):\n",
    "    return y_i - predict(x_i, beta)\n",
    "\n",
    "\n",
    "def squared_error(x_i, y_i, beta):\n",
    "    return error(x_i, y_i, beta) ** 2\n",
    "\n",
    "\n",
    "def squared_error_gradient(x_i, y_i, beta):\n",
    "    # the gradient corresponding to the ith squared error term\n",
    "    return [-2 * x_ij * error(x_i, y_i, beta)\n",
    "            for x_ij in x_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_beta(x, y):\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(squared_error, \n",
    "                               squared_error_gradient, \n",
    "                               x, y, \n",
    "                               beta_initial, \n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality of model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_r_squared(x, y, beta):\n",
    "    sum_of_squared_errors = sum(error(x_i, y_i, beta) ** 2\n",
    "                                for x_i, y_i in zip(x, y))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreat: data bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = get_sample(num_points = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data):\n",
    "    # randomly samples len(data) elements with replacement\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "\n",
    "def bootstrap_statistic(data, stats_fn, num_samples):\n",
    "    # evaluates stats_fn on num_samples bootstrap samples from data\n",
    "    return [stats_fn(bootstrap_sample(data)) \n",
    "            for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "                [random.random() for _ in range(50)] + \n",
    "                [200 + random.random() for _ in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.07565101416489,\n",
       " 100.08980118353116,\n",
       " 100.10318562796138,\n",
       " 100.11277317986861,\n",
       " 100.09628686158311,\n",
       " 100.1127831050407,\n",
       " 100.07565101416489,\n",
       " 100.28379858903477,\n",
       " 100.08338203945503,\n",
       " 100.11277317986861,\n",
       " 100.16024537862239,\n",
       " 100.15665938898962,\n",
       " 100.07969501074561,\n",
       " 100.10318562796138,\n",
       " 100.08338203945503,\n",
       " 100.13014734041147,\n",
       " 100.1127831050407,\n",
       " 100.08338203945503,\n",
       " 100.09628686158311,\n",
       " 100.08761706417543,\n",
       " 100.15665938898962,\n",
       " 100.07565101416489,\n",
       " 100.1127831050407,\n",
       " 100.06751074062068,\n",
       " 100.08980118353116,\n",
       " 100.07969501074561,\n",
       " 100.13014734041147,\n",
       " 100.16024537862239,\n",
       " 100.11836899667533,\n",
       " 100.1108869734438,\n",
       " 100.08338203945503,\n",
       " 100.08980118353116,\n",
       " 100.15665938898962,\n",
       " 100.07565101416489,\n",
       " 100.09628686158311,\n",
       " 100.10318562796138,\n",
       " 100.07565101416489,\n",
       " 100.05126724609055,\n",
       " 100.09628686158311,\n",
       " 100.06751074062068,\n",
       " 100.11836899667533,\n",
       " 100.1127831050407,\n",
       " 100.08980118353116,\n",
       " 100.04869930383559,\n",
       " 100.10318562796138,\n",
       " 100.13014734041147,\n",
       " 100.09628686158311,\n",
       " 100.08980118353116,\n",
       " 100.2065614098669,\n",
       " 100.08338203945503,\n",
       " 100.11277317986861,\n",
       " 100.1108869734438,\n",
       " 100.07565101416489,\n",
       " 100.11277317986861,\n",
       " 100.10318562796138,\n",
       " 100.11836899667533,\n",
       " 100.11836899667533,\n",
       " 100.07969501074561,\n",
       " 100.08761706417543,\n",
       " 100.16815320123185,\n",
       " 100.00794064252058,\n",
       " 100.1108869734438,\n",
       " 100.1108869734438,\n",
       " 100.07565101416489,\n",
       " 100.08761706417543,\n",
       " 100.1108869734438,\n",
       " 100.08761706417543,\n",
       " 100.08338203945503,\n",
       " 100.10318562796138,\n",
       " 100.06751074062068,\n",
       " 100.06751074062068,\n",
       " 100.1108869734438,\n",
       " 100.07565101416489,\n",
       " 100.04869930383559,\n",
       " 100.08761706417543,\n",
       " 100.07565101416489,\n",
       " 100.06751074062068,\n",
       " 100.1108869734438,\n",
       " 100.13014734041147,\n",
       " 100.08338203945503,\n",
       " 100.08761706417543,\n",
       " 100.1108869734438,\n",
       " 100.10318562796138,\n",
       " 100.11277317986861,\n",
       " 100.08980118353116,\n",
       " 100.04059992494805,\n",
       " 100.10318562796138,\n",
       " 100.16815320123185,\n",
       " 100.16815320123185,\n",
       " 100.11836899667533,\n",
       " 100.08338203945503,\n",
       " 100.11277317986861,\n",
       " 100.08761706417543,\n",
       " 100.08338203945503,\n",
       " 100.07969501074561,\n",
       " 100.1127831050407,\n",
       " 100.08980118353116,\n",
       " 100.1108869734438,\n",
       " 100.08761706417543,\n",
       " 100.08761706417543]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(close_to_100, median, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200.0580509438265,\n",
       " 100.34507757567151,\n",
       " 200.0580509438265,\n",
       " 100.34507757567151,\n",
       " 0.9882351487225011,\n",
       " 200.0467796859568,\n",
       " 200.25922692344722,\n",
       " 200.0456964935684,\n",
       " 0.9610312802396112,\n",
       " 200.0456964935684,\n",
       " 200.23941596018597,\n",
       " 0.9369691586445807,\n",
       " 0.9184820619953314,\n",
       " 100.34507757567151,\n",
       " 0.8383265651934163,\n",
       " 0.8007465903541809,\n",
       " 0.7315983062253606,\n",
       " 100.34507757567151,\n",
       " 200.25922692344722,\n",
       " 0.9805166506472687,\n",
       " 100.34507757567151,\n",
       " 0.9882351487225011,\n",
       " 200.19230954124467,\n",
       " 200.01243631882932,\n",
       " 0.9805166506472687,\n",
       " 0.8007465903541809,\n",
       " 100.34507757567151,\n",
       " 0.9665489030431832,\n",
       " 200.24013040782634,\n",
       " 0.9665489030431832,\n",
       " 200.17481948445143,\n",
       " 0.9610312802396112,\n",
       " 200.01243631882932,\n",
       " 200.00152422185673,\n",
       " 0.9369691586445807,\n",
       " 0.9184820619953314,\n",
       " 200.24013040782634,\n",
       " 0.9805166506472687,\n",
       " 0.9100160146990397,\n",
       " 200.23941596018597,\n",
       " 0.9805166506472687,\n",
       " 200.23941596018597,\n",
       " 0.9610312802396112,\n",
       " 0.8383265651934163,\n",
       " 200.01243631882932,\n",
       " 0.9805166506472687,\n",
       " 200.0467796859568,\n",
       " 200.23941596018597,\n",
       " 0.9665489030431832,\n",
       " 0.9665489030431832,\n",
       " 0.8383265651934163,\n",
       " 0.9882351487225011,\n",
       " 100.34507757567151,\n",
       " 200.19230954124467,\n",
       " 200.0456964935684,\n",
       " 200.0467796859568,\n",
       " 200.0456964935684,\n",
       " 200.00152422185673,\n",
       " 200.19230954124467,\n",
       " 200.17481948445143,\n",
       " 200.0467796859568,\n",
       " 0.9184820619953314,\n",
       " 200.23941596018597,\n",
       " 0.9610312802396112,\n",
       " 0.9610312802396112,\n",
       " 200.01243631882932,\n",
       " 0.9805166506472687,\n",
       " 200.00152422185673,\n",
       " 0.9100160146990397,\n",
       " 200.3114460010002,\n",
       " 200.0467796859568,\n",
       " 0.6976706401912388,\n",
       " 200.23941596018597,\n",
       " 200.01243631882932,\n",
       " 0.9805166506472687,\n",
       " 0.9882351487225011,\n",
       " 0.7314892207908478,\n",
       " 0.9100160146990397,\n",
       " 0.9882351487225011,\n",
       " 0.9882351487225011,\n",
       " 200.0456964935684,\n",
       " 0.9805166506472687,\n",
       " 200.28088316421835,\n",
       " 200.24013040782634,\n",
       " 200.01243631882932,\n",
       " 0.9882351487225011,\n",
       " 200.23941596018597,\n",
       " 0.9805166506472687,\n",
       " 0.9100160146990397,\n",
       " 200.00152422185673,\n",
       " 200.17481948445143,\n",
       " 0.9100160146990397,\n",
       " 200.01243631882932,\n",
       " 0.8159130965336595,\n",
       " 200.01243631882932,\n",
       " 0.9184820619953314,\n",
       " 0.9184820619953314,\n",
       " 0.9805166506472687,\n",
       " 0.9610312802396112,\n",
       " 100.34507757567151]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(far_from_100, median, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression coefficients standart errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sample_beta(sample):\n",
    "    x_sample, y_sample = zip(*sample) # magic unzipping trick\n",
    "    return estimate_beta(x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bootstrap_standart_errors = [\n",
    "    standart_deviation([beta[i] for beta in boottrap_betas])\n",
    "    for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(beta_hat_j, sigma_hat_j):\n",
    "    if beta_hat_j > 0:\n",
    "        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n",
    "    else:\n",
    "        return 2 * normal_cdf(beta_hat_j / sigma_hat_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is a hyperparameter controlling how harsh the penalty is\n",
    "# sometimes it's called lambda but that already means something in Python\n",
    "def ridge_penalty(beta, alpha):\n",
    "  return alpha * dot(beta[1:], beta[1:])\n",
    "\n",
    "\n",
    "def squared_error_ridge(x_i, y_i, beta, alpha):\n",
    "    # estimate error plus ridge penalty on beta\n",
    "    return error(x_i, y_i, beta) ** 2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "\n",
    "def ridge_penalty_gradient(beta, alpha):\n",
    "    # gradient of just the ridge penalty\n",
    "    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "\n",
    "def squared_error_ridge_gradient(x_i, y_i, beta, alpha):\n",
    "    # the gradient corresponding to the ith squared error term\n",
    "    # including the ridge penalty\n",
    "    return vector_add(squared_error_gradient(x_i, y_i, beta),\n",
    "                      ridge_penalty_gradient(beta, alpha))\n",
    "\n",
    "\n",
    "def estimate_beta_ridge(x, y, alpha):\n",
    "    # use gradient descent to fit a ridge regression\n",
    "    # with penalty alpha\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(partial(squared_error_ridge, alpha=alpha), \n",
    "                               partial(squared_error_ridge_gradient, \n",
    "                                       alpha=alpha), \n",
    "                               x, y, \n",
    "                               beta_initial, \n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_penalty(beta, alpha):\n",
    "    return alpha * sum(abs(beta_i) for beta_i in beta[1:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
